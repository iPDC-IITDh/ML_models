{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31c6e2f2",
   "metadata": {},
   "source": [
    "### Importing all necessary packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5f661c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.mixture\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fc6b48cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "799ca22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "rows = []\n",
    "with open(\"./generate_false_data.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file)\n",
    "    # header = next(csvreader)\n",
    "    for row in csvreader:\n",
    "        rows.append(row)\n",
    "# print(header)\n",
    "# print(rows)\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "# print(rows)\n",
    "\n",
    "for i in rows:\n",
    "    # print(i)\n",
    "    b = float(i[1])\n",
    "    c = float(i[2])\n",
    "    d = float(i[3])\n",
    "    e = float(i[4])\n",
    "    f = float(i[5])\n",
    "    g = float(i[6])\n",
    "    h = float(i[7])\n",
    "    p = float(i[8])\n",
    "    j = float(i[9])\n",
    "    k = float(i[10])\n",
    "    l = int(i[11])\n",
    "    x.append([b,c,d,e,f,g,h,p,j,k])\n",
    "    y.append(l)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.05, shuffle=True, random_state=0)\n",
    "\n",
    "# print(X_train)\n",
    "# print(y_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "193b5358",
   "metadata": {},
   "source": [
    "### Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0c6e30cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 1 of 2) Processing std, total=   0.0s\n",
      "[Pipeline] ..... (step 2 of 2) Processing Random_forest, total=   0.1s\n",
      "\n",
      "Accuracy: 1.0\n",
      "\n",
      "----------------Classification Report----------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        44\n",
      "   macro avg       1.00      1.00      1.00        44\n",
      "weighted avg       1.00      1.00      1.00        44\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe1 = Pipeline([ ('std', StandardScaler()), ('Random_forest', RandomForestClassifier(n_estimators = 100))], verbose = True)\n",
    "pipe1.fit(X_train, y_train)\n",
    "filename = \"./models/RF.sav\"\n",
    "pickle.dump(pipe1, open(filename, 'wb'))\n",
    "prob_score_RF=pipe1.predict_proba(X_test)\n",
    "print(\"\\nAccuracy:\",accuracy_score(y_test, pipe1.predict(X_test)))\n",
    "print(\"\\n----------------Classification Report----------------\\n\\n\",classification_report(y_test,pipe1.predict(X_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6f5fccc",
   "metadata": {},
   "source": [
    "#### Confusion Matrix for Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c6ba6a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18  0]\n",
      " [ 0 26]]\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.confusion_matrix(y_test, pipe1.predict(X_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "787e36fc",
   "metadata": {},
   "source": [
    "### Decision tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e822fde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 1 of 2) Processing std, total=   0.0s\n",
      "[Pipeline] ..... (step 2 of 2) Processing decision_tree, total=   0.0s\n",
      "\n",
      "Accuracy: 1.0\n",
      "\n",
      "----------------Classification Report----------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        44\n",
      "   macro avg       1.00      1.00      1.00        44\n",
      "weighted avg       1.00      1.00      1.00        44\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe2 = Pipeline([ ('std', StandardScaler()), ('decision_tree', DecisionTreeClassifier())], verbose = True)\n",
    "pipe2.fit(X_train, y_train)\n",
    "filename = \"./models/DT.sav\"\n",
    "pickle.dump(pipe2, open(filename, 'wb'))\n",
    "prob_score_DT=pipe2.predict_proba(X_test)\n",
    "print(\"\\nAccuracy:\",accuracy_score(y_test, pipe2.predict(X_test)))\n",
    "print(\"\\n----------------Classification Report----------------\\n\\n\",classification_report(y_test,pipe2.predict(X_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16f6c5d2",
   "metadata": {},
   "source": [
    "#### Confusion Matrix for Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0ac37fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18  0]\n",
      " [ 0 26]]\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.confusion_matrix(y_test, pipe2.predict(X_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d55092cd",
   "metadata": {},
   "source": [
    "### SVM (Support Vector Machine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c70bf876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 1 of 2) Processing std, total=   0.0s\n",
      "[Pipeline] ............... (step 2 of 2) Processing SVM, total=   0.0s\n",
      "\n",
      "Accuracy: 1.0\n",
      "\n",
      "----------------Classification Report----------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        44\n",
      "   macro avg       1.00      1.00      1.00        44\n",
      "weighted avg       1.00      1.00      1.00        44\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe4 = Pipeline([ ('std', StandardScaler()), ('SVM', SVC(kernel='rbf',probability=True) )], verbose = True)\n",
    "pipe4.fit(X_train, y_train)\n",
    "filename = \"./models/SVM.sav\"\n",
    "pickle.dump(pipe4, open(filename, 'wb'))\n",
    "prob_score_SVM=pipe4.predict_proba(X_test)\n",
    "print(\"\\nAccuracy:\",accuracy_score(y_test, pipe4.predict(X_test)))\n",
    "print(\"\\n----------------Classification Report----------------\\n\\n\",classification_report(y_test,pipe4.predict(X_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08bc05cb",
   "metadata": {},
   "source": [
    "#### Confusion matrix for SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1f0ad333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18  0]\n",
      " [ 0 26]]\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.confusion_matrix(y_test, pipe4.predict(X_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e3418e9",
   "metadata": {},
   "source": [
    "### Logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "19ca2ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 1 of 2) Processing std, total=   0.0s\n",
      "[Pipeline]  (step 2 of 2) Processing Logistic_Regression, total=   0.0s\n",
      "\n",
      "Accuracy: 0.5909090909090909\n",
      "\n",
      "----------------Classification Report----------------\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.83      0.62        18\n",
      "           1       0.79      0.42      0.55        26\n",
      "\n",
      "    accuracy                           0.59        44\n",
      "   macro avg       0.64      0.63      0.59        44\n",
      "weighted avg       0.67      0.59      0.58        44\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe5 = Pipeline([ ('std', StandardScaler()), ('Logistic_Regression', LogisticRegression(random_state = 0) )], verbose = True)\n",
    "pipe5.fit(X_train, y_train)\n",
    "filename = \"./models/LR.sav\"\n",
    "pickle.dump(pipe5, open(filename, 'wb'))\n",
    "prob_score_LR=pipe5.predict_proba(X_test)\n",
    "print(\"\\nAccuracy:\",accuracy_score(y_test, pipe5.predict(X_test)))\n",
    "print(\"\\n----------------Classification Report----------------\\n\\n\",classification_report(y_test,pipe5.predict(X_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10f4db2d",
   "metadata": {},
   "source": [
    "#### Confusion matrix for Logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "09faf51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15  3]\n",
      " [15 11]]\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.confusion_matrix(y_test, pipe5.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
